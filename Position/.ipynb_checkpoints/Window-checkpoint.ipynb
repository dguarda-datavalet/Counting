{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed3ee60-ee61-4ca6-bafd-c1c80116f6dc",
   "metadata": {},
   "source": [
    "## Window function\n",
    "### Description\n",
    "If you look at the whole dataset rtls_scout_raw we can see that there’s many different access point types and they all behave differently, so if I want the solution to be general It is imperative that we have this in mind and create a solution that take these differences for account.\n",
    "\n",
    "The complete window will be run on a 15 minute basis and the size of the window will be of 30 minutes, as to make sure we link things coherently and don’t miss devices going in or out.\n",
    "\n",
    "Here you see the overlapping windows being computed.\n",
    "\n",
    "In this 30-minute window as finely as 1 second per window computed depending on the input data.\n",
    "\n",
    "### Algorithm\n",
    "While there is data present in the windows:\n",
    "\n",
    "        For every window available:\n",
    "                If there is data available below and above the mid point of the window\n",
    "                          if the data is homogenous\n",
    "                         split the window in half\n",
    "                 If the window has no data available in one or both of the halves\n",
    "                         If it has a boundary that coincides with the total window boundary\n",
    "                                  Reduce the window boundary to a new one\n",
    "                         If there is no boundary that coincide with the total window boundary\n",
    "                                  the graph becomes perforated (is_perforated to true) and we store the empty\n",
    "                                  window into a list and repeat the step above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "4d4e7a41-32b1-48f4-8a09-a3e4097f88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import statistics as sts\n",
    "import numpy as np\n",
    "from statsmodels import robust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb87f1e-2f07-4de4-8201-9578190e19d0",
   "metadata": {},
   "source": [
    "## Result of light data exploration\n",
    "An associated device emits about every 10 timestamp on average but can vary on type of devices so a short window or even having a window at all seems redundant,  \n",
    "so the window will still be built for general purposes but relying the nodes will be done by seeking the lowest distance in the next Nth nodes (timestamp)  \n",
    "perhaps extensively but most likely by sampling observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "f0833ef3-39fc-4e9b-9d9a-37521a6cbfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def window(seq, n=2):\n",
    "    '''\n",
    "    Returns a sliding window (of width n) over data from the iterable\n",
    "       s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \n",
    "    '''\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "\n",
    "def mid_point(x1, x2):\n",
    "    return int((x1 + x2) / 2)\n",
    "        \n",
    "def correct_overlapping_index(tuple_array):\n",
    "    '''\n",
    "    Creates non overlapping values from tuple arrays and corrects the first tuple\n",
    "    '''\n",
    "    return [tuple_array[0]] + [(x[0]+1,x[1]) for x in tuple_array[1:]]   \n",
    "        \n",
    "def get_series_index(series, value, max_bool = True):\n",
    "    '''\n",
    "    Map value to corresponding index\n",
    "    '''\n",
    "    return (series[series >= value[0]].index[0], series[series <= value[1]].index[-1])\n",
    "\n",
    "def split_dict(series, master_dict):\n",
    "    resulting_dict = {}\n",
    "    for key, value in master_dict.items():\n",
    "        splitted_dict = split_window(series, key, value)\n",
    "        #merging dictionnaries\n",
    "        resulting_dict = {**resulting_dict, **splitted_dict}\n",
    "    return resulting_dict\n",
    " \n",
    "def split_window(series, tuple_value, tuple_index):\n",
    "    '''\n",
    "    Returns the corresponding mid point of value and maps it to the series object\n",
    "    '''\n",
    "    mid_value_list = [tuple_value[0], mid_point(tuple_value[0], tuple_value[1]), tuple_value[1]]\n",
    "    level_value_array = correct_overlapping_index(list(window(mid_value_list)))\n",
    "    # Initiating dict\n",
    "    value_index_dict = {}\n",
    "    # Map the two new values to the dataset itself and return indexes\n",
    "    for value_tuple in level_value_array:\n",
    "        value_index_dict[value_tuple] = get_series_index(series, value_tuple)\n",
    "        \n",
    "    return value_index_dict\n",
    "\n",
    "def calculate_variance(series, master_dict, sorting_column='Timestamp'):\n",
    "    '''\n",
    "    Computing variance of the resulting time series based on the slices computed from the split_window_function\n",
    "    '''\n",
    "    variance_list = []\n",
    "    for key, value in master_dict.items():\n",
    "        variance_list.append(abs(value[1]-value[0])) \n",
    "        \n",
    "    return robust.mad(variance_list), min(variance_list)  \n",
    "\n",
    "def fine_split_algorithm(starting_values, master_dict, min_value_len = 4, min_window_len = 3, min_iterations = 6, tolerance = 0):\n",
    "    '''\n",
    "    Splits a dataset in half until either:\n",
    "     - the mean absolute deviation increases and we reached at least a minimum amount of iteration\n",
    "     - We reach a minimum length of the window size\n",
    "    '''\n",
    "    #Initiating booleans for algorithm\n",
    "    stop_counter = 0\n",
    "    last_variance = np.inf\n",
    "    actual_iterations = 0\n",
    "    value_length = np.inf\n",
    "    window_length = np.inf\n",
    "\n",
    "    while(stop_counter<tolerance or min_iterations>actual_iterations or value_length>min_value_len):\n",
    "        master_dict = split_dict(starting_values, master_dict)\n",
    "        current_variance = calculate_variance(starting_values, master_dict)\n",
    "        if(current_variance[0] > last_variance):\n",
    "            stop_counter = stop_counter + 1\n",
    "        last_variance = current_variance[0]\n",
    "        value_length = current_variance[1]   \n",
    "        window_length = next(iter(master_dict))[1]-next(iter(master_dict))[0]\n",
    "        \n",
    "        if(stop_counter>tolerance and min_iterations<actual_iterations):\n",
    "            break    # break here\n",
    "        if(value_length<min_value_len):\n",
    "            break    # break here\n",
    "        if(window_length<min_window_len):\n",
    "            break    # break here\n",
    "        actual_iterations = actual_iterations + 1\n",
    "    return master_dict\n",
    "\n",
    "def generate_window_dict(dataset, sorting_column, window_size=1800, window_frequency=900, **kwargs):\n",
    "    '''\n",
    "    Takes a dataset and outputs a index based on args: min_window_len, min_iterations, tolerance\n",
    "    min_window_len: length of the window generated\n",
    "    min_iterations: wont stop until n iterations\n",
    "    tolerance: number of time until the algorithm stops when the variations keeps coming up\n",
    "    '''\n",
    "    starting_values = dataset.sort_values(sorting_column).reset_index()[sorting_column]\n",
    "    #initiating dictionnary\n",
    "    min_value, max_value = min(starting_values), max(starting_values)\n",
    "    master_dict = {}\n",
    "    #creating level 0 index and removing the overlap between the values\n",
    "    level_0 = range(min_value, max_value+window_frequency, window_frequency)\n",
    "    level0_index_array = correct_overlapping_index(list(window(level_0)))\n",
    "    \n",
    "    #mapping the value to the index\n",
    "    for tuple_array in level0_index_array:\n",
    "        master_dict[tuple_array] = get_series_index(starting_values, tuple_array)\n",
    "    \n",
    "    #running algorithm \n",
    "    master_dict = fine_split_algorithm(starting_values, master_dict, **kwargs)\n",
    "\n",
    "    return master_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0890dc-5076-4b9f-a395-a94e32d6ff1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
